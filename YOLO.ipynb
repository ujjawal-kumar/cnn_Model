{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO basic steps for implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset:- PASCAL-VOC2007\n",
    "   \n",
    "The twenty object classes that have been selected are:\n",
    "\n",
    "Person: person\n",
    "\n",
    "Animal: bird, cat, cow, dog, horse, sheep\n",
    "\n",
    "Vehicle: aeroplane, bicycle, boat, bus, car, motorbike, train\n",
    "\n",
    "Indoor: bottle, chair, dining table, potted plant, sofa, tv/monitor\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ujjawal/project/env1/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cnn_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(H,W,C,Y0):\n",
    "    X=tf.placeholder(tf.float32,shape=(None,H,W,C))\n",
    "    Y=tf.placeholder(tf.float32,shape=(None,Y0))\n",
    "    return X,Y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    tf.set_random_seed(1) \n",
    "    W1= tf.get_variable(\"W1\", [3,3,3,32], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W2= tf.get_variable(\"W2\", [3,3,32,64], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W3= tf.get_variable(\"W3\", [3,3,64,128], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W4= tf.get_variable(\"W4\", [3,3,128,64], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W5= tf.get_variable(\"W5\", [3,3,64,128], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W6= tf.get_variable(\"W6\", [3,3,128,256], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W7= tf.get_variable(\"W7\", [3,3,256,128], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W8= tf.get_variable(\"W8\", [3,3,128,256], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W9= tf.get_variable(\"W9\", [3,3,256,512], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W10= tf.get_variable(\"W10\", [3,3,512,256], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W11= tf.get_variable(\"W11\", [3,3,256,512], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W12= tf.get_variable(\"W12\", [3,3,512,256], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W13= tf.get_variable(\"W13\", [3,3,256,512], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W14= tf.get_variable(\"W14\", [3,3,512,1024], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W15= tf.get_variable(\"W15\", [3,3,1024,512], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W16= tf.get_variable(\"W16\", [3,3,512,1024], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W17 = tf.get_variable(\"W17\", [1,1,1024,512], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W18= tf.get_variable(\"W18\", [3,3,512,1024], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    W19= tf.get_variable(\"W19\", [3,3,1024,1000], initializer = tf.contrib.layers.xavier_initializer(seed = 0))\n",
    "    #W_1=tf.Variable(tf.constant(0.1,shape=[3,3,o_d,n_f]))\n",
    "    #W_3=tf.Variable(tf.constant(0.1,shape=[1,1,o_d,n_f]))\n",
    "    parameters = {\"W1\": W1,\"W2\": W2,\"W3\": W3,\"W4\": W4,\"W5\": W5,\"W6\": W6,\"W7\": W7,\"W8\": W8,\"W9\": W9,\"W10\": W10,\n",
    "                  \"W11\": W11,\"W12\": W12,\"W13\": W13,\"W14\": W14,\"W15\": W15,\"W16\": W16,\"W17\": W17,\"W18\": W18,\n",
    "                  \"W19\": W19}\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    W3 = parameters['W3']\n",
    "    W4 = parameters['W4']\n",
    "    W5 = parameters['W5']\n",
    "    W6 = parameters['W6']\n",
    "    W7 = parameters['W7']\n",
    "    W8 = parameters['W8']\n",
    "    W9 = parameters['W9']\n",
    "    W10 = parameters['W10']\n",
    "    W11 = parameters['W11']\n",
    "    W12= parameters['W12']\n",
    "    W13 = parameters['W13']\n",
    "    W14= parameters['W14']\n",
    "    W15 = parameters['W15']\n",
    "    W16 = parameters['W16']\n",
    "    W17= parameters['W17']\n",
    "    W18= parameters['W18']\n",
    "    W19= parameters['W19']\n",
    "   \n",
    "    Z1 = tf.nn.conv2d(X,W1, strides = [1,1,1,1], padding = 'SAME')\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    P1 = tf.nn.max_pool(A1, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'SAME')\n",
    "    \n",
    "    Z2 = tf.nn.conv2d(P1,W2, strides = [1,1,1,1], padding = 'SAME')\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    P2 = tf.nn.max_pool(A2, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'SAME')\n",
    "    \n",
    "    Z3 = tf.nn.conv2d(P2,W3, strides = [1,1,1,1], padding = 'SAME')\n",
    "    A3 = tf.nn.relu(Z3)\n",
    "    \n",
    "    Z4 = tf.nn.conv2d(A3,W4, strides = [1,1,1,1], padding = 'SAME')\n",
    "    A4 = tf.nn.relu(Z4)\n",
    "    \n",
    "    Z5 = tf.nn.conv2d(A4,W5, strides = [1,1,1,1], padding = 'SAME')\n",
    "    A5 = tf.nn.relu(Z5)\n",
    "    \n",
    "    P3 = tf.nn.max_pool(A5, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'SAME')\n",
    "    \n",
    "    Z6 = tf.nn.conv2d(P3,W6, strides = [1,1,1,1], padding = 'SAME')\n",
    "    A6 = tf.nn.relu(Z6)\n",
    "    \n",
    "    Z7 = tf.nn.conv2d(A6,W7, strides = [1,1,1,1], padding = 'SAME')\n",
    "    A7 = tf.nn.relu(Z7)\n",
    "    \n",
    "    Z8 = tf.nn.conv2d(A7,W8, strides = [1,1,1,1], padding = 'SAME')\n",
    "    A8 = tf.nn.relu(Z8)\n",
    "    \n",
    "    P4 = tf.nn.max_pool(A8, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'SAME')\n",
    "    \n",
    "    Z9 = tf.nn.conv2d(P4,W9, strides = [1,1,1,1], padding = 'SAME')\n",
    "    A9 = tf.nn.relu(Z9)\n",
    "    \n",
    "    Z10 = tf.nn.conv2d(A9,W10, strides = [1,1,1,1], padding = 'SAME')\n",
    "    A10 = tf.nn.relu(Z10)\n",
    "    \n",
    "    Z11 = tf.nn.conv2d(A10,W11, strides = [1,1,1,1], padding = 'SAME')\n",
    "    A11= tf.nn.relu(Z11)\n",
    "    \n",
    "    Z12= tf.nn.conv2d(A11,W12, strides = [1,1,1,1], padding = 'SAME')\n",
    "    A12= tf.nn.relu(Z12)\n",
    "    \n",
    "    Z13 = tf.nn.conv2d(A12,W13, strides = [1,1,1,1], padding = 'SAME')\n",
    "    A13 = tf.nn.relu(Z13)\n",
    "    \n",
    "    \n",
    "    P5 = tf.nn.max_pool(A13, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'SAME')\n",
    "    \n",
    "    Z14 = tf.nn.conv2d(P5,W14, strides = [1,1,1,1], padding = 'SAME')\n",
    "    A14= tf.nn.relu(Z14)\n",
    "    \n",
    "    Z15= tf.nn.conv2d(A14,W15, strides = [1,1,1,1], padding = 'SAME')\n",
    "    A15= tf.nn.relu(Z15)\n",
    "    \n",
    "    Z16= tf.nn.conv2d(A15,W16, strides = [1,1,1,1], padding = 'SAME')\n",
    "    A16= tf.nn.relu(Z16)\n",
    "    \n",
    "    Z17= tf.nn.conv2d(A16,W17, strides = [1,1,1,1], padding = 'SAME')\n",
    "    A17= tf.nn.relu(Z17)\n",
    "    \n",
    "    Z18 = tf.nn.conv2d(A17,W18, strides = [1,1,1,1], padding = 'SAME')\n",
    "    A18 = tf.nn.relu(Z18)\n",
    "    \n",
    "    Z19 = tf.nn.conv2d(A18,W19, strides = [1,1,1,1], padding = 'SAME')\n",
    "    A19= tf.nn.relu(Z19)\n",
    "    \n",
    "    P6=tf.nn.avg_pool(A19,ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'SAME')\n",
    "    \n",
    "    P6 = tf.contrib.layers.flatten(P6)\n",
    "    \n",
    "    Z20 = tf.contrib.layers.fully_connected(P6, 1000, activation_fn=None)\n",
    "\n",
    "    return Z20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'fully_connected/BiasAdd:0' shape=(?, 1000) dtype=float32>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Z20, Y):\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = Z20, labels = Y))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.009,\n",
    "          num_epochs = 100, minibatch_size = 64, print_cost = True):\n",
    "    \n",
    "    ops.reset_default_graph() \n",
    "    tf.set_random_seed(1)\n",
    "    \n",
    "    seed = 3\n",
    "    \n",
    "    (m, n_H0, n_W0, n_C0) = X_train.shape             \n",
    "    n_y = Y_train.shape[1]                            \n",
    "    costs = []  \n",
    "    \n",
    "    X, Y = create_placeholders(n_H0, n_W0, n_C0, n_y)\n",
    "    \n",
    "    parameters = initialize_parameters()\n",
    "    Z20 = forward_propagation(X, parameters)\n",
    "    cost = compute_cost(Z20, Y)\n",
    "    \n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "    \n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "   \n",
    "        sess.run(init)\n",
    "        \n",
    "      \n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            minibatch_cost = 0.\n",
    "            num_minibatches = int(m / minibatch_size)\n",
    "            seed = seed + 1\n",
    "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "            for minibatch in minibatches:\n",
    "\n",
    "                \n",
    "                (minibatch_X, minibatch_Y) = minibatch\n",
    "                \n",
    "                _ , temp_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
    "              \n",
    "                \n",
    "                minibatch_cost += temp_cost / num_minibatches\n",
    "                \n",
    "\n",
    "           \n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                print (\"Cost after epoch %i: %f\" % (epoch, minibatch_cost))\n",
    "            if print_cost == True and epoch % 1 == 0:\n",
    "                costs.append(minibatch_cost)\n",
    "        \n",
    "        \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs))\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "\n",
    "        # Calculate the correct predictions\n",
    "        predict_op = tf.argmax(Z3, 1)\n",
    "        correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
    "        \n",
    "        # Calculate accuracy on the test set\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "        print(accuracy)\n",
    "        train_accuracy = accuracy.eval({X: X_train, Y: Y_train})\n",
    "        test_accuracy = accuracy.eval({X: X_test, Y: Y_test})\n",
    "        print(\"Train Accuracy:\", train_accuracy)\n",
    "        print(\"Test Accuracy:\", test_accuracy)\n",
    "                \n",
    "        return train_accuracy, test_accuracy, parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
